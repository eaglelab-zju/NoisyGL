model:
  method: r2lp
  n_hidden: 64
  n_layer: 2
  act: F.relu
  dropout: 0.5
  norm_info: ~
  input_layer: false
  output_layer: false

  alpha: 0.0
  beta: 1.0
  gamma: 0.0
  delta: 0.0
  norm_layers: 2
  orders: 1
  orders_func_id: 2
  norm_func_id: 1
  alpha1: 0.6
  alpha2: 0.0
  alpha3: 0.1
  pre_select: 0.2

training:
  lr: 1e-2
  weight_decay: 5e-4
  n_epochs: 200
  n_epochs_lp: 20
  patience: ~
  criterion: metric
  pre_unknown: 0.5
  pre_select: 0.5

dataset:
  sparse: true

analysis:
  flag: false
  project: gnn-with-label-noise
  save_graph: false